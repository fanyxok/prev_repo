{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Learning Algorithm\n",
    "\n",
    "The perceptron is a simple supervised machine learning algorithm and one of the earliest neural network architectures. It was introduced by Rosenblatt in the late 1950s. A perceptron represents a binary linear classifier that maps a set of training examples (of $d$ dimensional input vectors) onto binary output values using a $d-1$ dimensional hyperplane. But Today, we will implement **Multi-Classes Perceptron Learning Algorithm** \n",
    "**Given:**\n",
    "* dataset $\\{(x^i, y^i)\\}$, $i \\in (1, M)$\n",
    "* $x^i$ is $d$ dimension vector, $x^i = (x^i_1, \\dots x^i_d)$\n",
    "* $y^i$ is multi-class target varible $y^i \\in \\{0,1,2\\}$\n",
    "\n",
    "A perceptron is trained using gradient descent. The training algorithm has different steps. In the beginning (step 0) the model parameters are initialized. The other steps (see below) are repeated for a specified number of training iterations or until the parameters have converged.\n",
    "\n",
    "**Step0:** Initial the weight vector and bias with zeros     \n",
    "**Step1:** Compute the linear combination of the input features and weight. $y^i_{pred} = \\arg\\max_k W_k*x^i + b$    \n",
    "**Step2:** Compute the gradients for parameters $W_k$, $b$. **Derive the parameter update equation Here (5 points)**   \n",
    "\n",
    "##################################     \n",
    "TODO: Derive you answer hear\n",
    "#################################\n",
    "\n",
    "For the i-th sample and k-th class's weight:\n",
    "\n",
    "$f_{m}=(Wx_{i}+b)_{m}$\n",
    "\n",
    "$Loss_{i}=max_{k}(f_{k})-f_{y_i}$                              \n",
    "\n",
    "$\\frac{\\partial L_{i}}{\\partial f_{m}}=\\frac{\\partial max_{k}(f_k) - f_{y_i}}{\\partial f_m}=\\frac{\\partial max_{k}(f_k)}{\\partial f_m}-\\frac{\\partial f_{y_i}}{\\partial f_m}$        \n",
    "It has 4 cases:\n",
    "- when $m==y_i$ and it m is max, it is 0;\n",
    "- $m == y_i$ and it m is not max, it it -1;\n",
    "- $m != y_i$ and it m is max, it it 1;\n",
    "- $m != y_i$ and it m is not max, it it 0;\n",
    "\n",
    "$\\frac{\\partial f_{m}}{\\partial W_{k}} = x_{i}$\n",
    "\n",
    "$\\frac{\\partial f_{m}}{\\partial b{k}} = 1$\n",
    "\n",
    "$\\frac{\\partial L_{i}}{\\partial W_{k}} = \\frac{\\partial L_{i}}{\\partial f_{m}} \\times \\frac{\\partial f_{m}}{\\partial W_{k}} =   x_{i} \\text{ or } -x_{i} \\text{ or } 0$ \n",
    "\n",
    "When $W_k$ classify correctly, the gredient of $W_k$ is 0; Otherwise, the gradient is $-x_{i}$ for $W_{y_i}$ and $x_{i}$ for $W_{k}$;\n",
    "\n",
    "$\\frac{\\partial L_{i}}{\\partial b_{k}} = \\frac{\\partial L_{i}}{\\partial f_{m}} \\times \\frac{\\partial f_{m}}{\\partial b_{k}} =   1 \\text{ or } -1 \\text{ or } 0$ \n",
    "\n",
    "When $b_k$ classify correctly, the gredient of $b_k$ is 0; Otherwise, the gradient is $-1$ for $b_{y_i}$ and $1$ for $b_{k}$;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "X_Shape: (150, 4)\n",
      "y_Shape: (150,)\n",
      "Label Space: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "print(type(X))\n",
    "y = iris.target\n",
    "y = np.array(y)\n",
    "print('X_Shape:', X.shape)\n",
    "print('y_Shape:', y.shape)\n",
    "print('Label Space:', np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_Shape: (105, 4)\n",
      "X_test_Shape: (45, 4)\n",
      "y_train_Shape: (105,)\n",
      "y_test_Shape: (45, 4)\n"
     ]
    }
   ],
   "source": [
    "## split the training set and test set\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3, random_state=0)\n",
    "print('X_train_Shape:', X_train.shape)\n",
    "print('X_test_Shape:',  X_test.shape)\n",
    "print('y_train_Shape:', y_train.shape)\n",
    "print('y_test_Shape:',  X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClsPLA(object):\n",
    "    \n",
    "    ## We recommend to absorb the bias into weight.  W = [w, b]\n",
    "    \n",
    "    def __init__(self, X_train, y_train, X_test, y_test, lr, num_epoch, weight_dimension, num_cls):\n",
    "        super(MultiClsPLA, self).__init__()\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.weight = self.initial_weight(weight_dimension, num_cls)\n",
    "        self.sample_mean = np.mean(self.X_train, 0)\n",
    "        self.sample_std = np.std(self.X_train, 0)\n",
    "        self.num_epoch = num_epoch\n",
    "        self.lr = lr\n",
    "        self.total_acc_train = []\n",
    "        self.total_acc_tst = []\n",
    "          \n",
    "    def initial_weight(self, weight_dimension, num_cls):\n",
    "        weight = None\n",
    "        #########################################\n",
    "        ##  ToDO: Initialize the weight with   ##\n",
    "        ##  small std and zero mean gaussian   ##\n",
    "        #########################################\n",
    "        w = 0.001*np.random.randn(weight_dimension,num_cls)\n",
    "        b = 0.001*np.random.randn(1, num_cls)\n",
    "        weight = np.concatenate( (w,b), axis = 0)\n",
    "\n",
    "        return weight\n",
    "        \n",
    "    def data_preprocessing(self, data):\n",
    "        #####################################\n",
    "        ##  ToDO: Normlize the data        ##\n",
    "        #####################################\n",
    "        norm_data = (data-self.sample_mean)/self.sample_std\n",
    "        #norm_data /= np.sum(norm_data, axis=1).reshape(-1,1)\n",
    "        return norm_data\n",
    "    \n",
    "    def train_step(self, X_train, y_train, shuffle_idx):\n",
    "        np.random.shuffle(shuffle_idx)\n",
    "        X_train = X_train[shuffle_idx]\n",
    "        y_train = y_train[shuffle_idx]\n",
    "        train_acc = None\n",
    "        ##############################################\n",
    "        ## TODO: to implement the training process  ##\n",
    "        ## and update the weights                   ##\n",
    "        ##############################################\n",
    "\n",
    "        def score(x, w):\n",
    "            return np.dot(x, w)\n",
    "        \n",
    "        # s = score(X_train, self.weight)\n",
    "        # y = np.max(s,axis = 1).reshape(-1,1)    \n",
    "\n",
    "        # b = s[np.arange(np.size(y_train)), y_train.astype(int).flatten()].reshape(-1,1)    \n",
    "\n",
    "        # loss = np.sum(y - b)\n",
    "        # loss = loss + 1e-5*np.linalg.norm(self.weight[:,:-1],'fro')**2\n",
    "        # loss /=float(np.size(y))\n",
    "        # forward to output\n",
    "        s = np.dot(X_train, self.weight)\n",
    "        y = np.max(s,axis = 1).reshape(-1,1)   \n",
    "        b = s[np.arange(np.size(y_train)), y_train.astype(int).flatten() ]\n",
    "\n",
    "        # loss\n",
    "        loss = np.sum(y - b)\n",
    "        reg = 1e-3\n",
    "        loss += 0.5 * reg * np.sum(self.weight * self.weight)\n",
    "        loss /= X_train.shape[0]\n",
    "        \n",
    "        # gredient and update\n",
    "        y_pred = np.argmax(s, axis=1)\n",
    "\n",
    "        ds = np.zeros_like(s)\n",
    "\n",
    "        # fyi not max,  1\n",
    "        ds[np.arange(np.size(y_train))[y_pred != y_train], y_train[y_pred != y_train]] = -1\n",
    "\n",
    "        # fm not fyi, is max,  -1\n",
    "        ds[np.arange(np.size(y_train))[y_pred != y_train], y_pred[y_pred != y_train]] = 1\n",
    "\n",
    "        dW = X_train[:, :-1].T.dot(ds)\n",
    "        #ds[np.arange(np.size(y_train)), y_train.astype(int).flatten()] -= 1*2\n",
    "        #dW = X_train[:,:-1].T.dot(ds)\n",
    "        #db = np.array( [np.sum(s, axis=0)]) \n",
    "        db = np.array( [np.sum(ds, axis = 0)]) \n",
    "\n",
    "        dW = np.concatenate((dW,db), axis=0)\n",
    "\n",
    "        dW /=  X_train.shape[0] \n",
    "        dW += reg * self.weight\n",
    "        self.weight -= self.lr * dW\n",
    "\n",
    "        # acc\n",
    "        s = np.dot(X_train, self.weight)\n",
    "        y_pred = np.argmax(s, axis=1)\n",
    "        train_acc = (y_pred == y_train).mean()\n",
    "        return train_acc\n",
    "        \n",
    "    def test_step(self, X_test, y_test):\n",
    "        \n",
    "        \n",
    "        X_test = self.data_preprocessing(data=X_test)\n",
    "        num_sample = X_test.shape[0]\n",
    "        test_acc = None\n",
    "        X_test = np.column_stack( (X_test, [1]*num_sample))\n",
    "        #########################################\n",
    "        ##  ToDO: Evaluate the test set and    ##\n",
    "        ##  return the test acc                ##\n",
    "        #########################################\n",
    "        s = np.dot(X_test, self.weight)\n",
    "\n",
    "        # save acc\n",
    "        y_pred = np.argmax(s, axis=1)\n",
    "        test_acc = (y_pred == y_test).mean()\n",
    "           \n",
    "        return test_acc\n",
    "        \n",
    "    def train(self):\n",
    "           \n",
    "        self.X_train = self.data_preprocessing(data=self.X_train)\n",
    "        num_sample = self.X_train.shape[0]\n",
    "        \n",
    "        ######################################################\n",
    "        ### TODO: In order to absorb the bias into weights ###\n",
    "        ###  we need to modify the input data.             ###\n",
    "        ###  So You need to transform the input data       ###\n",
    "        ######################################################\n",
    "        self.X_train = np.column_stack( (self.X_train, [1]*num_sample))\n",
    "        \n",
    "        shuffle_index = np.array(range(0, num_sample))\n",
    "        for epoch in range(self.num_epoch):\n",
    "            training_acc = self.train_step(X_train=self.X_train, y_train=self.y_train, shuffle_idx=shuffle_index)\n",
    "            tst_acc = self.test_step(X_test=self.X_test,  y_test=self.y_test)\n",
    "            self.total_acc_train.append(training_acc)\n",
    "            self.total_acc_tst.append(tst_acc)\n",
    "            print('epoch:', epoch, 'traing_acc:%.3f'%training_acc, 'tst_acc:%.3f'%tst_acc)\n",
    "    \n",
    "    def vis_acc_curve(self):\n",
    "        train_acc = np.array(self.total_acc_train)\n",
    "        tst_acc = np.array(self.total_acc_tst)\n",
    "        plt.plot(train_acc)\n",
    "        plt.plot(tst_acc)\n",
    "        plt.legend(['train_acc', 'tst_acc'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 traing_acc:0.657 tst_acc:0.600\n",
      "epoch: 1 traing_acc:0.686 tst_acc:0.622\n",
      "epoch: 2 traing_acc:0.790 tst_acc:0.800\n",
      "epoch: 3 traing_acc:0.867 tst_acc:0.844\n",
      "epoch: 4 traing_acc:0.895 tst_acc:0.867\n",
      "epoch: 5 traing_acc:0.905 tst_acc:0.889\n",
      "epoch: 6 traing_acc:0.905 tst_acc:0.889\n",
      "epoch: 7 traing_acc:0.914 tst_acc:0.889\n",
      "epoch: 8 traing_acc:0.914 tst_acc:0.933\n",
      "epoch: 9 traing_acc:0.914 tst_acc:0.933\n",
      "epoch: 10 traing_acc:0.914 tst_acc:0.933\n",
      "epoch: 11 traing_acc:0.924 tst_acc:0.956\n",
      "epoch: 12 traing_acc:0.933 tst_acc:0.978\n",
      "epoch: 13 traing_acc:0.933 tst_acc:0.956\n",
      "epoch: 14 traing_acc:0.952 tst_acc:0.978\n",
      "epoch: 15 traing_acc:0.943 tst_acc:0.978\n",
      "epoch: 16 traing_acc:0.943 tst_acc:0.978\n",
      "epoch: 17 traing_acc:0.952 tst_acc:0.978\n",
      "epoch: 18 traing_acc:0.962 tst_acc:0.978\n",
      "epoch: 19 traing_acc:0.952 tst_acc:0.978\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "#######################################################\n",
    "### TODO: \n",
    "### 1. You need to import the model and pass some parameters. \n",
    "### 2. Then training the model with some epoches.\n",
    "### 3. Visualize the training acc and test acc verus epoches\n",
    "\n",
    "# X_train 4 features, 150 samples\n",
    "# y_train 1 label,  3 classes\n",
    "learn_rate = 0.001\n",
    "epochs = 20\n",
    "nclass = len(np.unique(y_train))\n",
    "\n",
    "dweight = X_train.shape[1]\n",
    "\n",
    "mcp = MultiClsPLA(X_train, y_train, X_test, y_test, learn_rate, epochs, dweight, nclass)\n",
    "mcp.train()\n",
    "mcp.vis_acc_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f4b740b2018a3ec4603a0693cfbd747f4c3bfc12b03fc5f3119df88c73c1b9e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('dl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
